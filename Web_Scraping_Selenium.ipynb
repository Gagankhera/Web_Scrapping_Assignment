{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f0c1ccc",
   "metadata": {},
   "source": [
    "# Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a157567",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "driver = webdriver.Chrome('C:/chromedriver')\n",
    "\n",
    "url = 'https://www.naukri.com/' \n",
    "driver.get(url)\n",
    "\n",
    "# Finding element for job title bar and searching for required info\n",
    "search_job = driver.find_element_by_xpath(\"//input[@class='sugInp']\")\n",
    "search_job.send_keys(\"Data Analyst\")\n",
    "\n",
    "# Finding element for job location bar and searching for required info\n",
    "search_job= driver.find_element_by_id(\"qsb-location-sugg\")\n",
    "search_job.send_keys(\"Bangalore\")\n",
    "\n",
    "# clicking the search button using xpath function\n",
    "search_btn = driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "search_btn.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b420114e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 20 20\n"
     ]
    }
   ],
   "source": [
    "# Creating a list to append the fetched data\n",
    "job_titles = []\n",
    "company_names = []\n",
    "location = []\n",
    "Experience_list = []\n",
    "\n",
    "for i in driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\"):\n",
    "    job_titles.append(i.text)\n",
    "for i in  driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\"):\n",
    "    company_names.append(i.text)\n",
    "for i in driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']//span[1]\"):\n",
    "    location.append(i.text)\n",
    "for i in  driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']//span\"):\n",
    "    Experience_list.append(i.text)\n",
    "\n",
    "print(len(job_titles),len(company_names),len(location),len(Experience_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c9dcc90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Business Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Trigent Software</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Business Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Trigent Software</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Analyst IDAM Services</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>GlaxoSmithKline Pharmaceuticals Limited</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst/Sr.Data Engineer</td>\n",
       "      <td>Hyderabad/Secunderabad, Chennai, Bangalore/Ben...</td>\n",
       "      <td>SYREN TECHNOLOGIES PRIVATE LIMITED</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Business Data Analyst - Google Data Studio &amp; SQL</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>AVE-Promagne</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst - Python/SQL</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Affine</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Executive Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Gokaldas Exports Ltd</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Gurgaon/Gurugram...</td>\n",
       "      <td>Virtusa Consulting Services Pvt Ltd</td>\n",
       "      <td>8-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Systems and Data Analyst, Safety and Provisioning</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>AECOM India Private Limited</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst with SQL</td>\n",
       "      <td>Noida, Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>Wipro Limited</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_title  \\\n",
       "0                              Business Data Analyst   \n",
       "1                              Business Data Analyst   \n",
       "2                  Senior Data Analyst IDAM Services   \n",
       "3                      Data Analyst/Sr.Data Engineer   \n",
       "4   Business Data Analyst - Google Data Studio & SQL   \n",
       "5                          Data Analyst - Python/SQL   \n",
       "6                             Executive Data Analyst   \n",
       "7                                Senior Data Analyst   \n",
       "8  Systems and Data Analyst, Safety and Provisioning   \n",
       "9                              Data Analyst with SQL   \n",
       "\n",
       "                                        Job_location  \\\n",
       "0                                Bangalore/Bengaluru   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3  Hyderabad/Secunderabad, Chennai, Bangalore/Ben...   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7  Hyderabad/Secunderabad, Pune, Gurgaon/Gurugram...   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9       Noida, Gurgaon/Gurugram, Bangalore/Bengaluru   \n",
       "\n",
       "                              Company_name Experience_required  \n",
       "0                         Trigent Software            5-10 Yrs  \n",
       "1                         Trigent Software            5-10 Yrs  \n",
       "2  GlaxoSmithKline Pharmaceuticals Limited             4-8 Yrs  \n",
       "3       SYREN TECHNOLOGIES PRIVATE LIMITED             4-9 Yrs  \n",
       "4                             AVE-Promagne             3-8 Yrs  \n",
       "5                                   Affine             3-5 Yrs  \n",
       "6                     Gokaldas Exports Ltd             0-3 Yrs  \n",
       "7      Virtusa Consulting Services Pvt Ltd            8-12 Yrs  \n",
       "8              AECOM India Private Limited             2-7 Yrs  \n",
       "9                            Wipro Limited             3-5 Yrs  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating dataframe to store the fetched data\n",
    "jobs = pd.DataFrame({})\n",
    "jobs['Job_title'] = job_titles[:10]\n",
    "jobs['Job_location'] = location[:10]\n",
    "jobs['Company_name'] = company_names[:10]\n",
    "jobs['Experience_required'] = Experience_list[:10]\n",
    "jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d009f2",
   "metadata": {},
   "source": [
    "# Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location,company_name, full job-description. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c0fb51a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "driver = webdriver.Chrome('C:/chromedriver')\n",
    "driver.get('https://www.naukri.com/data-scientist-jobs-in-banglore?k=data%20scientist&l=banglore')\n",
    "\n",
    "# Fetching Urls\n",
    "urls = []\n",
    "for i in driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\"):\n",
    "    urls.append(i.get_attribute(\"href\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97ea980d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af9d5c47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "# Creating lists to append the fetched data\n",
    "job_title = []\n",
    "company_names = []\n",
    "location = []\n",
    "job_description = []\n",
    "\n",
    "for i in urls[:10]:\n",
    "    driver.get(i)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    # fetching job-title\n",
    "    try:\n",
    "        job = driver.find_element_by_xpath(\"//h1[@class='jd-header-title']\")\n",
    "        job_title.append(job.text.replace(\"\\n\",\"new line\"))\n",
    "    except:\n",
    "        job_title.append(\"_\")\n",
    "        \n",
    "    # fetching company_name\n",
    "    try:\n",
    "        job = driver.find_element_by_xpath(\"//div[@class='jd-header-comp-name']\")\n",
    "        company_names.append(job.text)\n",
    "    except:\n",
    "        company_names.append(\"_\")\n",
    "     \n",
    "    # fetching job-location\n",
    "    try:\n",
    "        job = driver.find_element_by_xpath(\"//title[@class='Jobs in Bangalore/Bengaluru']\")\n",
    "        location.append(job.text)\n",
    "    except:\n",
    "        location.append(\"_\")\n",
    "        \n",
    "    # Fetching Job_description\n",
    "    try:\n",
    "        job_des = driver.find_element_by_xpath(\"//section[@class='job-desc']\")\n",
    "        job_description.append(job_des.text)\n",
    "    except:\n",
    "        job_description.append(\"_\")\n",
    "\n",
    "print(len(job_title),len(company_names),len(location),len(job_description))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e23b8ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Job_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>_</td>\n",
       "      <td>Airbnb4.3(35 Reviews)</td>\n",
       "      <td>Job description\\nResponsibilities include:\\nDe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SENIOR DATA SCIENTIST</td>\n",
       "      <td>_</td>\n",
       "      <td>Happiest Minds Technologies Pvt.Ltd4.0(258 Rev...</td>\n",
       "      <td>Job description\\n  Skills\\nRequired Skills: Da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Requirement For Data Scientist - Mumbai &amp; Bang...</td>\n",
       "      <td>_</td>\n",
       "      <td>CRISIL LIMITED3.6(600 Reviews)</td>\n",
       "      <td>Job description\\n\\nCRISIL (formerly Credit Rat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hiring For Data Scientist / Statistical Analyst</td>\n",
       "      <td>_</td>\n",
       "      <td>ManpowerGroup Services India Private Limited</td>\n",
       "      <td>Job description\\nDepartment- BIRS (Business In...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>_</td>\n",
       "      <td>Philips India Limited4.0(517 Reviews)</td>\n",
       "      <td>Job description\\nUse predictive modeling to in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>_</td>\n",
       "      <td>NeenOpal Intelligent Solutions Private Limited</td>\n",
       "      <td>Job description\\nRoles and Responsibilities\\nW...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>_</td>\n",
       "      <td>PRESCIENCE DECISION SOLUTIONS PRIVATE LIMITED</td>\n",
       "      <td>Job description\\nHi,\\n\\nWe at Prescience www.p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>_</td>\n",
       "      <td>ELPIS IT SOLUTIONS PVT LTD3.3(6 Reviews)</td>\n",
       "      <td>Job description\\nRoles and Responsibilities\\nJ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_title Job_location  \\\n",
       "0                                                  _            _   \n",
       "1                                                  _            _   \n",
       "2                              Senior Data Scientist            _   \n",
       "3                              SENIOR DATA SCIENTIST            _   \n",
       "4  Requirement For Data Scientist - Mumbai & Bang...            _   \n",
       "5    Hiring For Data Scientist / Statistical Analyst            _   \n",
       "6                           Associate Data Scientist            _   \n",
       "7                                     Data Scientist            _   \n",
       "8                                     Data Scientist            _   \n",
       "9                                     Data Scientist            _   \n",
       "\n",
       "                                        Company_name  \\\n",
       "0                                                  _   \n",
       "1                                                  _   \n",
       "2                              Airbnb4.3(35 Reviews)   \n",
       "3  Happiest Minds Technologies Pvt.Ltd4.0(258 Rev...   \n",
       "4                     CRISIL LIMITED3.6(600 Reviews)   \n",
       "5       ManpowerGroup Services India Private Limited   \n",
       "6              Philips India Limited4.0(517 Reviews)   \n",
       "7     NeenOpal Intelligent Solutions Private Limited   \n",
       "8      PRESCIENCE DECISION SOLUTIONS PRIVATE LIMITED   \n",
       "9           ELPIS IT SOLUTIONS PVT LTD3.3(6 Reviews)   \n",
       "\n",
       "                                     Job_description  \n",
       "0                                                  _  \n",
       "1                                                  _  \n",
       "2  Job description\\nResponsibilities include:\\nDe...  \n",
       "3  Job description\\n  Skills\\nRequired Skills: Da...  \n",
       "4  Job description\\n\\nCRISIL (formerly Credit Rat...  \n",
       "5  Job description\\nDepartment- BIRS (Business In...  \n",
       "6  Job description\\nUse predictive modeling to in...  \n",
       "7  Job description\\nRoles and Responsibilities\\nW...  \n",
       "8  Job description\\nHi,\\n\\nWe at Prescience www.p...  \n",
       "9  Job description\\nRoles and Responsibilities\\nJ...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating dataframe to store the fetched data\n",
    "job = pd.DataFrame({})\n",
    "job['Job_title'] = job_title[:10]\n",
    "job['Job_location'] = location[:10]\n",
    "job['Company_name'] = company_names[:10]\n",
    "job['Job_description'] = job_description[:10]\n",
    "job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e496ab6",
   "metadata": {},
   "source": [
    "# Q3: In this question you have to scrape data using the filters available on the webpage "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bc97b8",
   "metadata": {},
   "source": [
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company_name,\n",
    "experience_required.\n",
    "The location filter to be used is “Delhi/NCR”\n",
    "The salary filter to be used is “3-6” lakhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea51c3d4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "driver = webdriver.Chrome('C:/chromedriver')\n",
    "driver.get('https://www.naukri.com/data-scientist-jobs?k=data%20scientist')\n",
    "\n",
    "# Clicking the location filter button \n",
    "filter_btn = driver.find_elements_by_xpath(\"//span[@title='Delhi / NCR']\")\n",
    "for i in filter_btn:\n",
    "    if i.text =='Delhi / NCR':\n",
    "        i.click()\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "# Clicking the salary filter button \n",
    "filter_sal_btn = driver.find_element_by_xpath(\"//span[@title='3-6 Lakhs']\")\n",
    "filter_sal_btn.click()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dce0457b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 20 20\n"
     ]
    }
   ],
   "source": [
    "# Creating a list to append the fetched data\n",
    "job_title = []\n",
    "location = []\n",
    "company_names = []\n",
    "experience_required = []\n",
    "\n",
    "for i in driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\"):\n",
    "    job_title.append(i.text)\n",
    "    \n",
    "for i in  driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\"):\n",
    "    company_names.append(i.text)\n",
    "    \n",
    "for i in driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']//span[1]\"):\n",
    "    location.append(i.text)\n",
    "    \n",
    "for i in  driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']//span\"):\n",
    "    experience_required.append(i.text)\n",
    "\n",
    "print(len(job_title),len(company_names),len(location),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86f7a08c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Only Fresher / Data Scientist / Data Analyst /...</td>\n",
       "      <td>Noida, Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "      <td>GABA Consultancy services</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst/Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...</td>\n",
       "      <td>Skillenable Fintech Private Limited</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>PROCESS NINE TECHNOLOGIES PVT.LTD.</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist - WFH - MIND Infotech</td>\n",
       "      <td>Pune, Chennai, Bangalore/Bengaluru, Delhi / NC...</td>\n",
       "      <td>MOTHERSONSUMI INFOTECH &amp; DESIGNS LIMITED</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist/ Machine Learning Engineer</td>\n",
       "      <td>Mohali/SAS Nagar, Hyderabad/Secunderabad, Ahme...</td>\n",
       "      <td>Creative Hands HR Consultancy</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist / Data Analyst / Business Analy...</td>\n",
       "      <td>Noida, New Delhi, Gurgaon/Gurugram</td>\n",
       "      <td>GABA Consultancy services</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist / Data Analyst</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>CARS24</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Immediate Openings For Data Scientist For Wipr...</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>IDESLABS PRIVATE LIMITED</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>R Systems International Ltd.</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi / NCR(Okhla)</td>\n",
       "      <td>Kusum Healthcare Pvt. Ltd.</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_title  \\\n",
       "0  Only Fresher / Data Scientist / Data Analyst /...   \n",
       "1                        Data Analyst/Data Scientist   \n",
       "2                                     Data Scientist   \n",
       "3               Data Scientist - WFH - MIND Infotech   \n",
       "4          Data Scientist/ Machine Learning Engineer   \n",
       "5  Data Scientist / Data Analyst / Business Analy...   \n",
       "6                      Data Scientist / Data Analyst   \n",
       "7  Immediate Openings For Data Scientist For Wipr...   \n",
       "8                                     Data Scientist   \n",
       "9                                     Data Scientist   \n",
       "\n",
       "                                        Job_location  \\\n",
       "0               Noida, Gurgaon/Gurugram, Delhi / NCR   \n",
       "1  Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...   \n",
       "2                                   Gurgaon/Gurugram   \n",
       "3  Pune, Chennai, Bangalore/Bengaluru, Delhi / NC...   \n",
       "4  Mohali/SAS Nagar, Hyderabad/Secunderabad, Ahme...   \n",
       "5                 Noida, New Delhi, Gurgaon/Gurugram   \n",
       "6                                   Gurgaon/Gurugram   \n",
       "7                                   Gurgaon/Gurugram   \n",
       "8                                              Noida   \n",
       "9                                 Delhi / NCR(Okhla)   \n",
       "\n",
       "                               Company_name Experience_required  \n",
       "0                 GABA Consultancy services             0-0 Yrs  \n",
       "1       Skillenable Fintech Private Limited             2-5 Yrs  \n",
       "2        PROCESS NINE TECHNOLOGIES PVT.LTD.             1-3 Yrs  \n",
       "3  MOTHERSONSUMI INFOTECH & DESIGNS LIMITED             3-7 Yrs  \n",
       "4             Creative Hands HR Consultancy             0-0 Yrs  \n",
       "5                 GABA Consultancy services             0-0 Yrs  \n",
       "6                                    CARS24             1-5 Yrs  \n",
       "7                  IDESLABS PRIVATE LIMITED            5-10 Yrs  \n",
       "8              R Systems International Ltd.             3-6 Yrs  \n",
       "9                Kusum Healthcare Pvt. Ltd.             4-6 Yrs  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating dataframe to store the fetched data\n",
    "job = pd.DataFrame({})\n",
    "job['Job_title'] = job_title[:10]\n",
    "job['Job_location'] = location[:10]\n",
    "job['Company_name'] = company_names[:10]\n",
    "job['Experience_required'] = experience_required[:10]\n",
    "job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26295a50",
   "metadata": {},
   "source": [
    "# Q4: Write a python program to scrape data for first 10 job results for Data scientist Designation in Noida location. You have to scrape company_name, No. of days ago when job was posted, Rating of the company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b187ad6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "driver = webdriver.Chrome('C:/chromedriver')\n",
    "driver.get('https://www.glassdoor.co.in/Job/noida-data-scientist-jobs-SRCH_IL.0,5_IC4477468_KO6,20.htm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c47be9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating lists to append the fetched data\n",
    "company_name = []\n",
    "No_of_days_ago = []\n",
    "rating_of_the_company = []\n",
    "\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='d-flex justify-content-between align-items-start']\"):\n",
    "    company_name.append(i.text)\n",
    "        \n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='d-flex align-items-end pl-std css-17n8uzw']\"):\n",
    "    No_of_days_ago.append(i.text)\n",
    "\n",
    "\n",
    "for i in driver.find_elements_by_xpath(\"//span[@class=' job-search-key-srfzj0 e1cjmv6j0']\"):\n",
    "    rating_of_the_company.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2015324f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30 20\n"
     ]
    }
   ],
   "source": [
    "print(len(company_name),len(No_of_days_ago),len(rating_of_the_company))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "900cab2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_name</th>\n",
       "      <th>No_of_days_ago</th>\n",
       "      <th>rating_of_the_company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Liberin Technologies Private Limited</td>\n",
       "      <td>30d+</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Noisy Lion</td>\n",
       "      <td>24h</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AlgoScale Technologies Private Limited</td>\n",
       "      <td>14d</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Grail Insights</td>\n",
       "      <td>24h</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lenskart</td>\n",
       "      <td>2d</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Innovacer</td>\n",
       "      <td>30d+</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Grail Insights</td>\n",
       "      <td>24h</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>IBM</td>\n",
       "      <td>19d</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Salasar New Age Technologies</td>\n",
       "      <td>30d+</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Newgen Software</td>\n",
       "      <td>30d+</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Company_name No_of_days_ago rating_of_the_company\n",
       "0    Liberin Technologies Private Limited           30d+                   3.9\n",
       "1                              Noisy Lion            24h                   3.5\n",
       "2  AlgoScale Technologies Private Limited            14d                   3.6\n",
       "3                          Grail Insights            24h                   3.8\n",
       "4                                Lenskart             2d                   3.5\n",
       "5                               Innovacer           30d+                   3.9\n",
       "6                          Grail Insights            24h                   3.3\n",
       "7                                     IBM            19d                   3.8\n",
       "8            Salasar New Age Technologies           30d+                   4.1\n",
       "9                         Newgen Software           30d+                   3.8"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating dataframe to store the fetched data\n",
    "job = pd.DataFrame({})\n",
    "job['Company_name'] = company_name[:10]\n",
    "job['No_of_days_ago'] = No_of_days_ago[:10]\n",
    "job['rating_of_the_company'] = rating_of_the_company[:10]\n",
    "job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fc14dc",
   "metadata": {},
   "source": [
    "# Q5: Write a python program to scrape the salary data for Data Scientist designation in Noida location.You have to scrape Company name, Number of salaries, Average salary, Minsalary, Max Salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3b85b2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "driver = webdriver.Chrome('C:/chromedriver')\n",
    "driver.get('https://www.glassdoor.co.in/Salaries/index.htm')\n",
    "\n",
    "# Finding element for job title bar\n",
    "search_job = driver.find_element_by_xpath(\"//input[@class='keyword']\")\n",
    "search_job.send_keys(\"Data Scientist\")\n",
    "\n",
    "# Finding element for job location bar\n",
    "search_job= driver.find_element_by_id(\"LocationSearch\")\n",
    "search_job.clear()\n",
    "search_job.send_keys(\"Noida\")\n",
    "\n",
    "# clicking the search button using xpath function\n",
    "search_btn = driver.find_element_by_xpath('//button[@class=\"gd-btn-mkt\"]')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b6005f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 20 20 20 20\n"
     ]
    }
   ],
   "source": [
    "# Creating lists to append the fetched data\n",
    "company_name = []\n",
    "Number_of_salaries = []\n",
    "Average_salary = []\n",
    "Min_Salary = []\n",
    "Max_Salary = []\n",
    "Rating = []\n",
    "\n",
    "for i in  driver.find_elements_by_xpath(\"//a[@class='css-f3vw95 e1aj7ssy3']\"):\n",
    "    company_name.append(i.text)\n",
    "    \n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='col-12 col-lg-auto']\"):\n",
    "    Number_of_salaries.append(i.text)\n",
    "    \n",
    "for i in  driver.find_elements_by_xpath(\"//div[@class='col-12 col-lg-4 px-lg-0 d-flex align-items-baseline']//h3\"):\n",
    "    Average_salary.append(i.text)\n",
    "\n",
    "for i in  driver.find_elements_by_xpath(\"//div[@class='d-flex mt-xxsm css-79elbk epuxyqn0']/p[1]\"):\n",
    "    Min_Salary.append(i.text)\n",
    "\n",
    "for i in  driver.find_elements_by_xpath(\"//div[@class='d-flex mt-xxsm css-79elbk epuxyqn0']/p[2]\"):\n",
    "    Max_Salary.append(i.text)\n",
    "    \n",
    "for i in  driver.find_elements_by_xpath(\"//span[@class='m-0 css-kyx745']\"):\n",
    "    Rating.append(i.text)    \n",
    "    \n",
    "\n",
    "print(len(company_name),len(Number_of_salaries),len(Average_salary),len(Min_Salary),len(Max_Salary),len(Rating))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9eb8aa63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>Number_of_salaries</th>\n",
       "      <th>Average_salary</th>\n",
       "      <th>Min_Salary</th>\n",
       "      <th>Max_Salary</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>21 salaries</td>\n",
       "      <td>₹6,19,349</td>\n",
       "      <td>₹4L</td>\n",
       "      <td>₹13L</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IBM</td>\n",
       "      <td>20 salaries</td>\n",
       "      <td>₹9,00,000</td>\n",
       "      <td>₹1L</td>\n",
       "      <td>₹28L</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>15 salaries</td>\n",
       "      <td>₹11,71,012</td>\n",
       "      <td>₹6L</td>\n",
       "      <td>₹22L</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Delhivery</td>\n",
       "      <td>15 salaries</td>\n",
       "      <td>₹12,26,283</td>\n",
       "      <td>₹5L</td>\n",
       "      <td>₹1Cr</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>14 salaries</td>\n",
       "      <td>₹7,44,116</td>\n",
       "      <td>₹4L</td>\n",
       "      <td>₹16L</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>14 salaries</td>\n",
       "      <td>₹12,80,000</td>\n",
       "      <td>₹8L</td>\n",
       "      <td>₹15L</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Optum</td>\n",
       "      <td>10 salaries</td>\n",
       "      <td>₹13,29,677</td>\n",
       "      <td>₹8L</td>\n",
       "      <td>₹20L</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Optum Global Solutions</td>\n",
       "      <td>10 salaries</td>\n",
       "      <td>₹14,28,139</td>\n",
       "      <td>₹10L</td>\n",
       "      <td>₹17L</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Valiance Solutions</td>\n",
       "      <td>10 salaries</td>\n",
       "      <td>₹8,69,449</td>\n",
       "      <td>₹5L</td>\n",
       "      <td>₹15L</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EXL Service</td>\n",
       "      <td>9 salaries</td>\n",
       "      <td>₹11,10,000</td>\n",
       "      <td>₹6L</td>\n",
       "      <td>₹15L</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                company_name Number_of_salaries Average_salary Min_Salary  \\\n",
       "0  Tata Consultancy Services        21 salaries      ₹6,19,349        ₹4L   \n",
       "1                        IBM        20 salaries      ₹9,00,000        ₹1L   \n",
       "2                  Accenture        15 salaries     ₹11,71,012        ₹6L   \n",
       "3                  Delhivery        15 salaries     ₹12,26,283        ₹5L   \n",
       "4         Ericsson-Worldwide        14 salaries      ₹7,44,116        ₹4L   \n",
       "5         UnitedHealth Group        14 salaries     ₹12,80,000        ₹8L   \n",
       "6                      Optum        10 salaries     ₹13,29,677        ₹8L   \n",
       "7     Optum Global Solutions        10 salaries     ₹14,28,139       ₹10L   \n",
       "8         Valiance Solutions        10 salaries      ₹8,69,449        ₹5L   \n",
       "9                EXL Service         9 salaries     ₹11,10,000        ₹6L   \n",
       "\n",
       "  Max_Salary Rating  \n",
       "0       ₹13L    3.9  \n",
       "1       ₹28L    3.9  \n",
       "2       ₹22L    4.1  \n",
       "3       ₹1Cr    3.8  \n",
       "4       ₹16L      4  \n",
       "5       ₹15L    3.7  \n",
       "6       ₹20L    3.7  \n",
       "7       ₹17L    3.9  \n",
       "8       ₹15L    4.2  \n",
       "9       ₹15L    3.6  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating dataframe to store the fetched data\n",
    "jobs = pd.DataFrame({})\n",
    "jobs['company_name'] = company_name[:10]\n",
    "jobs['Number_of_salaries'] = Number_of_salaries[:10]\n",
    "jobs['Average_salary'] = Average_salary[:10]\n",
    "jobs['Min_Salary'] = Min_Salary[:10]\n",
    "jobs['Max_Salary'] = Max_Salary[:10]\n",
    "jobs['Rating'] = Rating[:10]\n",
    "jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50937e41",
   "metadata": {},
   "source": [
    "# Q6 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. Discount %\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f29370d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "driver = webdriver.Chrome('C:/chromedriver')\n",
    "driver.get('https://www.flipkart.com')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf712631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# searching the input panel\n",
    "input_btn=driver.find_element_by_xpath(\"//div[@class='_3OO5Xc']/input\")\n",
    "input_btn.send_keys('sunglasses')\n",
    "\n",
    "# clicking the search button using xpath function \n",
    "btn=driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e02a80af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.flipkart.com/search?q=sunglasses&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off&page=1',\n",
       " 'https://www.flipkart.com/search?q=sunglasses&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off&page=1',\n",
       " 'https://www.flipkart.com/search?q=sunglasses&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off&page=2',\n",
       " 'https://www.flipkart.com/search?q=sunglasses&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off&page=3',\n",
       " 'https://www.flipkart.com/search?q=sunglasses&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off&page=4',\n",
       " 'https://www.flipkart.com/search?q=sunglasses&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off&page=5',\n",
       " 'https://www.flipkart.com/search?q=sunglasses&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off&page=6',\n",
       " 'https://www.flipkart.com/search?q=sunglasses&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off&page=7',\n",
       " 'https://www.flipkart.com/search?q=sunglasses&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off&page=8',\n",
       " 'https://www.flipkart.com/search?q=sunglasses&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off&page=9',\n",
       " 'https://www.flipkart.com/search?q=sunglasses&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off&page=10',\n",
       " 'https://www.flipkart.com/search?q=sunglasses&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off&page=3']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping all urls from flipkart web page.\n",
    "page_url=[] #empty list\n",
    "url=driver.find_elements_by_xpath(\"//nav[@class='yFHi8N']/a\")\n",
    "for i in url:\n",
    "    page_url.append(i.get_attribute(\"href\"))\n",
    "page_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ecb362d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping data of sunglass brand\n",
    "sun_brand=[] #empty list\n",
    "for i in page_url:\n",
    "    driver.get(i)\n",
    "    brand_tags=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "    for i in brand_tags:\n",
    "        sun_brand.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "870d6027",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping data of sunglass product description\n",
    "sun_pro_des=[] #empty list\n",
    "for i in page_url:\n",
    "    driver.get(i)\n",
    "    pro_des_tags=driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "    for i in pro_des_tags:\n",
    "        sun_pro_des.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "12ae6c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping data of sunglass price\n",
    "sun_price=[] #empty list\n",
    "for i in page_url:\n",
    "    driver.get(i)\n",
    "    pri_tags=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "    for i in pri_tags:\n",
    "        sun_price.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af422a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping data of sunglass discount\n",
    "sun_discount=[] #empty list\n",
    "for i in page_url:\n",
    "    driver.get(i)\n",
    "    dis_tags=driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']//span\")\n",
    "    for i in dis_tags:\n",
    "        sun_discount.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d59011ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AISLIN</td>\n",
       "      <td>Polarized, UV Protection Round Sunglasses (49)</td>\n",
       "      <td>₹525</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>elegante</td>\n",
       "      <td>UV Protection, Gradient Wayfarer, Clubmaster S...</td>\n",
       "      <td>₹449</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "      <td>₹237</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection Round Sunglasses (54)</td>\n",
       "      <td>₹329</td>\n",
       "      <td>86% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SHAAH COLLECTIONS</td>\n",
       "      <td>UV Protection, Polarized, Mirrored Rectangular...</td>\n",
       "      <td>₹198</td>\n",
       "      <td>88% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>AISLIN</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (32)</td>\n",
       "      <td>₹906</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection, Riding Glasses, Mirrored Wayfar...</td>\n",
       "      <td>₹210</td>\n",
       "      <td>83% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>GANSTA</td>\n",
       "      <td>Toughened Glass Lens, UV Protection Aviator Su...</td>\n",
       "      <td>₹266</td>\n",
       "      <td>86% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>PHENOMENAL</td>\n",
       "      <td>UV Protection Round Sunglasses (53)</td>\n",
       "      <td>₹399</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>GANSTA</td>\n",
       "      <td>UV Protection, Night Vision, Riding Glasses, G...</td>\n",
       "      <td>₹396</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Brand                                        Description  \\\n",
       "0              AISLIN     Polarized, UV Protection Round Sunglasses (49)   \n",
       "1            elegante  UV Protection, Gradient Wayfarer, Clubmaster S...   \n",
       "2              PIRASO              UV Protection Aviator Sunglasses (54)   \n",
       "3           Elligator                UV Protection Round Sunglasses (54)   \n",
       "4   SHAAH COLLECTIONS  UV Protection, Polarized, Mirrored Rectangular...   \n",
       "..                ...                                                ...   \n",
       "95             AISLIN             UV Protection Wayfarer Sunglasses (32)   \n",
       "96          Elligator  UV Protection, Riding Glasses, Mirrored Wayfar...   \n",
       "97             GANSTA  Toughened Glass Lens, UV Protection Aviator Su...   \n",
       "98         PHENOMENAL                UV Protection Round Sunglasses (53)   \n",
       "99             GANSTA  UV Protection, Night Vision, Riding Glasses, G...   \n",
       "\n",
       "   Price Discount  \n",
       "0   ₹525  65% off  \n",
       "1   ₹449  70% off  \n",
       "2   ₹237  85% off  \n",
       "3   ₹329  86% off  \n",
       "4   ₹198  88% off  \n",
       "..   ...      ...  \n",
       "95  ₹906  70% off  \n",
       "96  ₹210  83% off  \n",
       "97  ₹266  86% off  \n",
       "98  ₹399  80% off  \n",
       "99  ₹396  80% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating data frame for scraped data\n",
    "Sunglass=pd.DataFrame({})\n",
    "Sunglass['Brand']=sun_brand[:100]\n",
    "Sunglass['Description']=sun_prodes[:100]\n",
    "Sunglass['Price']=sun_price[:100]\n",
    "Sunglass['Discount']=sun_discount[:100]\n",
    "Sunglass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fd7398",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1007933",
   "metadata": {},
   "source": [
    "# Q7: : Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: https://www.flipkart.com/apple-iphone-11-black-64-gb-includesearpods-poweradapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec074ce9",
   "metadata": {},
   "source": [
    "1. Rating \n",
    "2. Review_summary \n",
    "3. Full review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a9358b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "driver = webdriver.Chrome('C:/chromedriver')\n",
    "driver.get('https://www.flipkart.com/apple-iphone-11-black-64-gb-includes\u0002earpods-power\u0002adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace')  \n",
    "\n",
    "# Fetching Urls\n",
    "url = driver.find_element_by_xpath(\"//div[@class='_3UAT2v _16PBlm']/span\")\n",
    "url.click()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "26663334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating lists to append the fetched data\n",
    "Rating = []\n",
    "Review_summary  = []\n",
    "Full_review = []\n",
    "\n",
    "for i in range(1,20):\n",
    "    \n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\"):\n",
    "        Rating.append(i.text)\n",
    "    \n",
    "    for i in driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\"):\n",
    "        Review_summary.append(i.text)\n",
    "    \n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']/div/div\"):\n",
    "        Full_review.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "3ae85e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190 190 190\n"
     ]
    }
   ],
   "source": [
    "print(len(Rating),len(Review_summary),len(Full_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5b7db8cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review_summary</th>\n",
       "      <th>Full_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money\\n\\nThe iPhone 11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.\\n\\nI’m am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>4</td>\n",
       "      <td>Good choice</td>\n",
       "      <td>So far it’s been an AMAZING experience coming ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>i11 is worthy to buy, too much happy with the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>iphone 11 is a very good phone to buy only if ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating       Review_summary  \\\n",
       "0       5            Brilliant   \n",
       "1       5       Simply awesome   \n",
       "2       5  Best in the market!   \n",
       "3       5     Perfect product!   \n",
       "4       5            Fabulous!   \n",
       "..    ...                  ...   \n",
       "95      5    Worth every penny   \n",
       "96      5        Great product   \n",
       "97      4          Good choice   \n",
       "98      5    Worth every penny   \n",
       "99      5   Highly recommended   \n",
       "\n",
       "                                          Full_review  \n",
       "0   The Best Phone for the Money\\n\\nThe iPhone 11 ...  \n",
       "1   Really satisfied with the Product I received.....  \n",
       "2   Great iPhone very snappy experience as apple k...  \n",
       "3   Amazing phone with great cameras and better ba...  \n",
       "4   This is my first iOS phone. I am very happy wi...  \n",
       "..                                                ...  \n",
       "95  Previously I was using one plus 3t it was a gr...  \n",
       "96  Amazing Powerful and Durable Gadget.\\n\\nI’m am...  \n",
       "97  So far it’s been an AMAZING experience coming ...  \n",
       "98  i11 is worthy to buy, too much happy with the ...  \n",
       "99  iphone 11 is a very good phone to buy only if ...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Review = pd.DataFrame({})\n",
    "Review['Rating'] = Rating[:100]\n",
    "Review['Review_summary'] = Review_summary[:100]\n",
    "Review['Full_review'] = Full_review[:100]\n",
    "Review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfac53e4",
   "metadata": {},
   "source": [
    "# Q8: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.\n",
    "You have to scrape 4 attributes of each sneaker :\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. discount %\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b0868af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "driver = webdriver.Chrome('C:/chromedriver')\n",
    "driver.get('https://www.flipkart.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6b6cb8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# searching the input panel\n",
    "input_btn=driver.find_element_by_xpath(\"//div[@class='_3OO5Xc']/input\")\n",
    "input_btn.send_keys('sneakers')\n",
    "\n",
    "# clicking the search button using xpath function \n",
    "btn=driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fa1d4eed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.flipkart.com/search?q=sneakers&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off&page=1',\n",
       " 'https://www.flipkart.com/search?q=sneakers&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off&page=2',\n",
       " 'https://www.flipkart.com/search?q=sneakers&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off&page=3',\n",
       " 'https://www.flipkart.com/search?q=sneakers&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off&page=4',\n",
       " 'https://www.flipkart.com/search?q=sneakers&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off&page=5',\n",
       " 'https://www.flipkart.com/search?q=sneakers&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off&page=6',\n",
       " 'https://www.flipkart.com/search?q=sneakers&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off&page=7',\n",
       " 'https://www.flipkart.com/search?q=sneakers&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off&page=8',\n",
       " 'https://www.flipkart.com/search?q=sneakers&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off&page=9',\n",
       " 'https://www.flipkart.com/search?q=sneakers&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off&page=10',\n",
       " 'https://www.flipkart.com/search?q=sneakers&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off&page=2']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping all urls from flipkart web page.\n",
    "page_url=[] #empty list\n",
    "url=driver.find_elements_by_xpath(\"//nav[@class='yFHi8N']//a\")\n",
    "for i in url:\n",
    "    page_url.append(i.get_attribute(\"href\"))\n",
    "page_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "85609ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping data of sneakers brand\n",
    "brands=[] #empty list\n",
    "for i in page_url:\n",
    "    driver.get(i)\n",
    "    brand_tags=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "    for i in brand_tags:\n",
    "        brands.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5a807c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping data of sneakers product description\n",
    "pro_description=[] #empty list\n",
    "for i in page_url:\n",
    "    driver.get(i)\n",
    "    des_tags=driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "    for i in des_tags:\n",
    "        pro_description.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "71857aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping data of sneakers price\n",
    "price=[] #empty list\n",
    "for i in page_url:\n",
    "    driver.get(i)\n",
    "    pri_tags=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "    for i in pri_tags:\n",
    "        price.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3057bee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping data of sneakers discount\n",
    "discount=[] #empty list\n",
    "for i in page_url:\n",
    "    driver.get(i)\n",
    "    dis_tags=driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']//span\")\n",
    "    for i in dis_tags:\n",
    "        discount.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "51363a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>HAWK21 Sneakers For Men</td>\n",
       "      <td>₹499</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Echor</td>\n",
       "      <td>Super Stylish &amp; Trendy Combo Pack of 02 Pairs ...</td>\n",
       "      <td>₹454</td>\n",
       "      <td>54% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Men Boxer Sneakers For Men</td>\n",
       "      <td>₹599</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Longwalk</td>\n",
       "      <td>Luxury Fashionable casual sneaker shoes Sneake...</td>\n",
       "      <td>₹266</td>\n",
       "      <td>46% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>luxury fashion</td>\n",
       "      <td>Perfect &amp; Affordable Combo Pack of 02 Pairs Sn...</td>\n",
       "      <td>₹379</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>White Sneaker For Men's/Boy's Sneakers For Men</td>\n",
       "      <td>₹499</td>\n",
       "      <td>57% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>SM-322 Sneakers For Men</td>\n",
       "      <td>₹1,847</td>\n",
       "      <td>44% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Wakefield</td>\n",
       "      <td>Simha IDP Sneakers For Men</td>\n",
       "      <td>₹210</td>\n",
       "      <td>57% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>Casual , Partywear Sneakers Shoes For Men's An...</td>\n",
       "      <td>₹379</td>\n",
       "      <td>24% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Fzzirok</td>\n",
       "      <td>HAWK21 Sneakers For Men</td>\n",
       "      <td>₹474</td>\n",
       "      <td>76% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                                Product description   Price  \\\n",
       "0     Robbie jones                            HAWK21 Sneakers For Men    ₹499   \n",
       "1            Echor  Super Stylish & Trendy Combo Pack of 02 Pairs ...    ₹454   \n",
       "2           Chevit                         Men Boxer Sneakers For Men    ₹599   \n",
       "3         Longwalk  Luxury Fashionable casual sneaker shoes Sneake...    ₹266   \n",
       "4   luxury fashion  Perfect & Affordable Combo Pack of 02 Pairs Sn...    ₹379   \n",
       "..             ...                                                ...     ...   \n",
       "95          Chevit     White Sneaker For Men's/Boy's Sneakers For Men    ₹499   \n",
       "96            PUMA                            SM-322 Sneakers For Men  ₹1,847   \n",
       "97       Wakefield                         Simha IDP Sneakers For Men    ₹210   \n",
       "98           BIRDE  Casual , Partywear Sneakers Shoes For Men's An...    ₹379   \n",
       "99         Fzzirok                            HAWK21 Sneakers For Men    ₹474   \n",
       "\n",
       "   Discount  \n",
       "0   50% off  \n",
       "1   54% off  \n",
       "2   62% off  \n",
       "3   46% off  \n",
       "4   70% off  \n",
       "..      ...  \n",
       "95  57% off  \n",
       "96  44% off  \n",
       "97  57% off  \n",
       "98  24% off  \n",
       "99  76% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating data frame for scraped data\n",
    "sneakers=pd.DataFrame({})\n",
    "sneakers['Brand']=brands[:100]\n",
    "sneakers['Product description']=pro_description[:100]\n",
    "sneakers['Price']=price[:100]\n",
    "sneakers['Discount']=discount[:100]\n",
    "sneakers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fff6b6",
   "metadata": {},
   "source": [
    "# Q9: Go to the link - https://www.myntra.com/shoesSet Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black” And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe description, price of the shoe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "486e247f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "driver = webdriver.Chrome('C:/chromedriver')\n",
    "driver.get('https://www.myntra.com/shoes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cd67df71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding price filter\n",
    "\n",
    "price_filter=driver.find_elements_by_xpath(\"//div[@class='vertical-filters-filters']\")\n",
    "for i in price_filter:\n",
    "    if i == 'Rs. 6649 to Rs. 13099':\n",
    "        i.click()\n",
    "time.sleep(2)\n",
    "\n",
    "#Adding color filter\n",
    "color_filter=driver.find_elements_by_xpath(\"//label[@class='common-checkboxIndicator']\")\n",
    "for i in color_filter:\n",
    "    if i == 'Black':\n",
    "        i.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a2f0920d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping shoe brand data\n",
    "br=driver.find_elements_by_xpath(\"//h3[@class='product-brand']\")\n",
    "\n",
    "brand=[] #empty list\n",
    "for i in range(1,4):\n",
    "    for j in br:\n",
    "        brand.append(j.text)\n",
    "    next_button=driver.find_element_by_xpath(\"//li[@class='pagination-next']/a\")\n",
    "    next_button.click\n",
    "    \n",
    "#Checking length of brand list\n",
    "len(brand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "025c285c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#short shoe description\n",
    "des=driver.find_elements_by_xpath(\"//h4[@class='product-product']\")\n",
    "\n",
    "description=[] #empty list\n",
    "for i in range(1,4):\n",
    "    for j in des:\n",
    "        description.append(j.text)\n",
    "    next_button=driver.find_element_by_xpath(\"//li[@class='pagination-next']/a\")\n",
    "    next_button.click\n",
    "    \n",
    "#Checking length of brand list\n",
    "len(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b5798bfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#scraping price of shoes\n",
    "pri_tags=driver.find_elements_by_xpath(\"//div[@class='product-price']\")\n",
    "\n",
    "\n",
    "price=[] #empty list\n",
    "for i in range(1,4):\n",
    "    for j in pri_tags:\n",
    "        price.append(j.text)\n",
    "    next_button=driver.find_element_by_xpath(\"//li[@class='pagination-next']/a\")\n",
    "    next_button.click\n",
    "\n",
    "\n",
    "#Checking length of price list\n",
    "len(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1a429f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product_Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Newfeel By Decathlon</td>\n",
       "      <td>Men Walking Shoes</td>\n",
       "      <td>Rs. 899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Provogue</td>\n",
       "      <td>Men Walking Sports Shoes</td>\n",
       "      <td>Rs. 699Rs. 3395(Rs. 2696 OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alishtezia</td>\n",
       "      <td>Women Colourblocked PU Sneakers</td>\n",
       "      <td>Rs. 799Rs. 1599(50% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Red Tape</td>\n",
       "      <td>Men Colourblocked PU Sneakers</td>\n",
       "      <td>Rs. 1379Rs. 4599(70% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sparx</td>\n",
       "      <td>Men SM-677 Running Shoes</td>\n",
       "      <td>Rs. 986Rs. 1049(6% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Red Tape</td>\n",
       "      <td>Men Woven Design Sneakers</td>\n",
       "      <td>Rs. 1319Rs. 4399(70% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>HRX by Hrithik Roshan</td>\n",
       "      <td>Men Chunky Sneaker</td>\n",
       "      <td>Rs. 1919Rs. 4799(60% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Red Tape</td>\n",
       "      <td>Men Air + Walking Shoes</td>\n",
       "      <td>Rs. 2189Rs. 7299(70% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>MENGLER</td>\n",
       "      <td>Men Walking Shoes</td>\n",
       "      <td>Rs. 649Rs. 2499(74% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>HRX by Hrithik Roshan</td>\n",
       "      <td>Men Front Runner Shoes</td>\n",
       "      <td>Rs. 1022Rs. 3299(69% OFF)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Brand              Product_Description  \\\n",
       "0    Newfeel By Decathlon                Men Walking Shoes   \n",
       "1                Provogue         Men Walking Sports Shoes   \n",
       "2              Alishtezia  Women Colourblocked PU Sneakers   \n",
       "3                Red Tape    Men Colourblocked PU Sneakers   \n",
       "4                   Sparx         Men SM-677 Running Shoes   \n",
       "..                    ...                              ...   \n",
       "95               Red Tape        Men Woven Design Sneakers   \n",
       "96  HRX by Hrithik Roshan               Men Chunky Sneaker   \n",
       "97               Red Tape          Men Air + Walking Shoes   \n",
       "98                MENGLER                Men Walking Shoes   \n",
       "99  HRX by Hrithik Roshan           Men Front Runner Shoes   \n",
       "\n",
       "                            Price  \n",
       "0                         Rs. 899  \n",
       "1   Rs. 699Rs. 3395(Rs. 2696 OFF)  \n",
       "2        Rs. 799Rs. 1599(50% OFF)  \n",
       "3       Rs. 1379Rs. 4599(70% OFF)  \n",
       "4         Rs. 986Rs. 1049(6% OFF)  \n",
       "..                            ...  \n",
       "95      Rs. 1319Rs. 4399(70% OFF)  \n",
       "96      Rs. 1919Rs. 4799(60% OFF)  \n",
       "97      Rs. 2189Rs. 7299(70% OFF)  \n",
       "98       Rs. 649Rs. 2499(74% OFF)  \n",
       "99      Rs. 1022Rs. 3299(69% OFF)  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating dataframe to store the fetched data\n",
    "Shoes = pd.DataFrame({})\n",
    "Shoes['Brand'] = brand[:100]\n",
    "Shoes['Product_Description'] = description[:100]\n",
    "Shoes['Price'] = price[:100]\n",
    "Shoes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624c38ad",
   "metadata": {},
   "source": [
    "# Q10: Go to webpage https://www.amazon.in/ Enter “Laptop” in the search field and then click the search icon.Then set CPU Type filter to “Intel Core i7” and “Intel Core i9”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d58977",
   "metadata": {},
   "source": [
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes \n",
    "for each laptop:\n",
    "1. title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "10577e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "driver = webdriver.Chrome('C:/chromedriver')\n",
    "driver.get('https://www.amazon.in/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "affc1f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# searching the input panel\n",
    "input_btn=driver.find_element_by_id(\"twotabsearchtextbox\") \n",
    "input_btn.send_keys('Laptop')\n",
    "\n",
    "# clicking the search button using xpath function \n",
    "btn=driver.find_element_by_xpath('//span[@id=\"nav-search-submit-text\"]')\n",
    "btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "26675ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "#locating the core i7 filter\n",
    "filter_button=driver.find_elements_by_xpath(\"//a[@class='a-link-normal s-navigation-item']/span\")\n",
    "for i in filter_button:\n",
    "    if i.text=='Intel Core i7':\n",
    "        i.click()\n",
    "        break\n",
    "        \n",
    "#Locating the core i9 filter\n",
    "filter_button=driver.find_elements_by_xpath(\"//a[@class='a-link-normal s-navigation-item']/span\")\n",
    "for i in filter_button:\n",
    "    if i.text=='Intel Core i9':\n",
    "        i.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "98696833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating lists to append the fetched data\n",
    "Title = []\n",
    "Ratings  = []\n",
    "Price = []\n",
    "\n",
    "for i in range(1,20):\n",
    "    \n",
    "    for i in driver.find_elements_by_xpath(\"//span[@class='a-size-medium a-color-base a-text-normal']\"):\n",
    "        Title.append(i.text)\n",
    "    \n",
    "    for i in driver.find_elements_by_xpath(\"//span[@class='a-price-whole']\"):\n",
    "        Price.append(i.text)\n",
    "     \n",
    "    #locating Ratings\n",
    "    # Fetching Urls\n",
    "    urls = []\n",
    "    for i in driver.find_elements_by_xpath(\"//a[@class='a-link-normal a-text-normal']\"):\n",
    "        urls.append(i.get_attribute(\"href\"))\n",
    "        \n",
    "    for i in urls[:10]:\n",
    "        driver.get(i)\n",
    "        time.sleep(3)\n",
    "        \n",
    "        # fetching ratings\n",
    "        try:                                                                      \n",
    "            rating=driver.find_element_by_xpath(\"//span[@class='a-size-base a-nowrap']//span\")\n",
    "            Ratings.append(rating.text)\n",
    "        except NoSuchElementException:\n",
    "            Ratings.append(\" - \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "322dbc11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 190 220\n"
     ]
    }
   ],
   "source": [
    "print(len(Title),len(Ratings),len(Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9d4991d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HP Envy 11th Gen Core i7 Processor 13.3-inch (...</td>\n",
       "      <td>4.1 out of 5</td>\n",
       "      <td>1,23,300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mi Notebook Ultra 3K Resolution Display Intel ...</td>\n",
       "      <td>4.2 out of 5</td>\n",
       "      <td>76,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lenovo IdeaPad S540 11th Gen Intel Core i7 13....</td>\n",
       "      <td>4.3 out of 5</td>\n",
       "      <td>77,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASUS TUF Gaming F17 (2021), 17.3-inch (43.94 c...</td>\n",
       "      <td>-</td>\n",
       "      <td>1,13,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASUS TUF Dash F15 (2021), 15.6-inch (39.62 cms...</td>\n",
       "      <td>3.5 out of 5</td>\n",
       "      <td>87,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lenovo IdeaPad Gaming 3 Intel Core i7 10th Gen...</td>\n",
       "      <td>4.4 out of 5</td>\n",
       "      <td>73,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i7-1...</td>\n",
       "      <td>4.2 out of 5</td>\n",
       "      <td>57,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HP Pavilion 13(2021) 11th Gen Intel Core i7 La...</td>\n",
       "      <td>5 out of 5</td>\n",
       "      <td>96,300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HP Envy 11th Gen Core i7 Processor 13.3-inch (...</td>\n",
       "      <td>4.1 out of 5</td>\n",
       "      <td>1,23,300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mi Notebook Pro QHD+ IPS Anti Glare Display In...</td>\n",
       "      <td>4.6 out of 5</td>\n",
       "      <td>72,999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title       Ratings     Price\n",
       "0  HP Envy 11th Gen Core i7 Processor 13.3-inch (...  4.1 out of 5  1,23,300\n",
       "1  Mi Notebook Ultra 3K Resolution Display Intel ...  4.2 out of 5    76,999\n",
       "2  Lenovo IdeaPad S540 11th Gen Intel Core i7 13....  4.3 out of 5    77,990\n",
       "3  ASUS TUF Gaming F17 (2021), 17.3-inch (43.94 c...            -   1,13,990\n",
       "4  ASUS TUF Dash F15 (2021), 15.6-inch (39.62 cms...  3.5 out of 5    87,990\n",
       "5  Lenovo IdeaPad Gaming 3 Intel Core i7 10th Gen...  4.4 out of 5    73,990\n",
       "6  Mi Notebook Horizon Edition 14 Intel Core i7-1...  4.2 out of 5    57,990\n",
       "7  HP Pavilion 13(2021) 11th Gen Intel Core i7 La...    5 out of 5    96,300\n",
       "8  HP Envy 11th Gen Core i7 Processor 13.3-inch (...  4.1 out of 5  1,23,300\n",
       "9  Mi Notebook Pro QHD+ IPS Anti Glare Display In...  4.6 out of 5    72,999"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Laptop = pd.DataFrame({})\n",
    "Laptop['Title'] = Title[:10]\n",
    "Laptop['Ratings'] = Ratings[:10]\n",
    "Laptop['Price'] = Price[:10]\n",
    "Laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f25c6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
